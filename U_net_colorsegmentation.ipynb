{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wz891aK_BWL",
        "outputId": "675b1ad2-2051-4485-e491-23197eddd15f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow numpy matplotlib pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG4WE_Vz_O-2",
        "outputId": "f00e7ac6-b588-4a77-ae5f-5c2c21d1c50a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CSriidVr_UHK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_to_class = {\n",
        "    0: (255, 52, 255),  # Flat areas\n",
        "    1: (28, 230, 255),  # Areas close to water sources\n",
        "    2: (255, 74, 70),   # Steep areas\n",
        "    3: (0, 137, 65),    # Dense vegetation areas\n",
        "    4: (122, 73, 0),    # Occupied areas\n",
        "    5: (0, 111, 166),   # Restricted areas\n",
        "    6: (248, 226, 76),  # Agriculture areas\n",
        "    # 添加其他类别的映射\n",
        "}\n",
        "\n",
        "def color_mask_to_categorical(mask, color_to_class, num_classes):\n",
        "    mask_array = np.array(mask)\n",
        "    categorical_mask = np.zeros((mask_array.shape[0], mask_array.shape[1]), dtype=int)\n",
        "\n",
        "    for color, class_id in color_to_class.items():\n",
        "        matches = np.all(mask_array == np.array(color, dtype=np.uint8), axis=-1)\n",
        "        categorical_mask[matches] = class_id\n",
        "\n",
        "    return to_categorical(categorical_mask, num_classes=num_classes)\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size=(256, 256), num_classes=7):\n",
        "    try:\n",
        "        print(\"Opening image...\")\n",
        "        image = Image.open(image_path)\n",
        "        print(\"Resizing image...\")\n",
        "        image = image.resize(target_size)\n",
        "        print(\"Converting image to array and normalizing...\")\n",
        "        image = np.array(image) / 255.0\n",
        "\n",
        "        print(\"Opening mask...\")\n",
        "        mask = Image.open(mask_path)\n",
        "        print(\"Resizing mask...\")\n",
        "        mask = mask.resize(target_size)\n",
        "        print(\"Converting mask to categorical...\")\n",
        "        mask = modified_color_mask_to_categorical(mask, color_to_class, num_classes)\n",
        "\n",
        "        return image, mask\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "WGxZCIM9_Yhw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_size=(256, 256, 3), num_classes=7):\n",
        "    inputs = Input(input_size)\n",
        "    # Contracting Path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    # Expansive Path\n",
        "    u4 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c3)\n",
        "    u4 = concatenate([u4, c2])\n",
        "    c4 = Conv2D(32, (3, 3), activation='relu', padding='same')(u4)\n",
        "    u5 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    u5 = concatenate([u5, c1])\n",
        "    c5 = Conv2D(16, (3, 3), activation='relu', padding='same')(u5)\n",
        "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c5)\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JsDTjST0A4Ku"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def remap_mask(mask, remap_dict, default_value=0):\n",
        "    remapped_mask = np.zeros_like(mask)\n",
        "    for original_value, new_value in remap_dict.items():\n",
        "        remapped_mask[mask == original_value] = new_value\n",
        "    unknown_values = ~np.isin(mask, list(remap_dict.keys()))\n",
        "    remapped_mask[unknown_values] = default_value  # Assign default value to unknowns\n",
        "    return remapped_mask\n",
        "\n",
        "# Example of usage in your data generator\n",
        "def image_mask_generator(image_dir, mask_dir, batch_size, target_size=(256, 256), num_classes=7):\n",
        "    image_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.png')])\n",
        "    mask_paths = sorted([os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir) if fname.endswith('.png')])\n",
        "    total = len(image_paths)\n",
        "\n",
        "    # Example remapping dictionary\n",
        "    remap_dict = {i: i if i < 7 else 0 for i in range(280)}  # Mapping all other values to 0 or another logic\n",
        "\n",
        "    while True:\n",
        "        for start in range(0, total, batch_size):\n",
        "            end = min(start + batch_size, total)\n",
        "            batch_images = []\n",
        "            batch_masks = []\n",
        "            for img_path, mask_path in zip(image_paths[start:end], mask_paths[start:end]):\n",
        "                image = Image.open(img_path).resize(target_size)\n",
        "                mask = Image.open(mask_path).resize(target_size, resample=Image.NEAREST)\n",
        "\n",
        "                image = np.array(image, dtype=np.float32) / 255.0\n",
        "                mask = np.array(mask, dtype=np.uint8)\n",
        "\n",
        "                # Remap mask values\n",
        "                mask = remap_mask(mask, remap_dict, default_value=0)\n",
        "\n",
        "                mask = to_categorical(mask, num_classes=num_classes)\n",
        "\n",
        "                batch_images.append(image)\n",
        "                batch_masks.append(mask)\n",
        "\n",
        "            yield np.array(batch_images), np.array(batch_masks)"
      ],
      "metadata": {
        "id": "k1WM5wX02Iwp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def test_directory(path):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    generator = datagen.flow_from_directory(\n",
        "        path,\n",
        "        class_mode=None,\n",
        "        batch_size=8,\n",
        "        target_size=(256, 256))\n",
        "    return generator\n",
        "\n",
        "# 测试图像目录\n",
        "image_test_gen = test_directory('/content/drive/MyDrive/ML/UNET/model/')\n",
        "# 测试掩码目录\n",
        "mask_test_gen = test_directory('/content/drive/MyDrive/ML/UNET/model/')\n",
        "\n",
        "def image_mask_generator(image_dir, mask_dir, batch_size):\n",
        "    # 创建两个数据生成器，一个用于图像，一个用于掩码\n",
        "    image_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    mask_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # 对图像和掩码进行相同的随机变换\n",
        "    seed = 1\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        image_dir,\n",
        "        class_mode=None,\n",
        "        batch_size=batch_size,\n",
        "        target_size=(256, 256),\n",
        "        seed=seed,\n",
        "        color_mode='rgb')  # 确保使用RGB模式读取图像\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        mask_dir,\n",
        "        class_mode=None,\n",
        "        batch_size=batch_size,\n",
        "        target_size=(256, 256),\n",
        "        seed=seed,\n",
        "        color_mode='grayscale')  # 如果掩码是单通道的，使用灰度模式\n",
        "\n",
        "    # 将图像和掩码组合成一个生成器\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    return train_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZdZPl3a5jew",
        "outputId": "b7911db2-1b21-40d7-e125-6328f3de8444"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 560 images belonging to 2 classes.\n",
            "Found 560 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# 定义随机映射函数\n",
        "def random_map(mask):\n",
        "    # 将掩码中多余的像素值随机映射到0-6之间\n",
        "    mask[mask > 6] = np.random.randint(0, 7)\n",
        "    return mask\n",
        "\n",
        "def test_directory(path):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    generator = datagen.flow_from_directory(\n",
        "        path,\n",
        "        class_mode=None,\n",
        "        batch_size=8,\n",
        "        target_size=(256, 256))\n",
        "    return generator\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "if560REA6RC3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/MyDrive/ML/UNET/modelimage/'\n",
        "mask_dir = '/content/drive/MyDrive/ML/UNET/modelmask/'\n",
        "\n",
        "# 创建模型\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 训练模型\n",
        "train_gen = image_mask_generator(image_dir, mask_dir, batch_size=8)\n",
        "model.fit(train_gen, steps_per_epoch=(280 // 8), epochs=10)\n",
        "model.save('path_to_save_model.h5')  # 保存模型\n",
        "model.save('path_to_save_model.h5')  # 保存模型"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkaVDkBlJI1q",
        "outputId": "28adfeef-e7eb-4cbe-f3af-042b0f9a3c3d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 280 images belonging to 1 classes.\n",
            "Found 280 images belonging to 1 classes.\n",
            "Epoch 1/10\n",
            "35/35 [==============================] - 89s 2s/step - loss: 50.0696 - accuracy: 0.3733\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - 87s 2s/step - loss: 44452.4727 - accuracy: 0.1677\n",
            "Epoch 3/10\n",
            "35/35 [==============================] - 89s 2s/step - loss: 4306579.0000 - accuracy: 0.1704\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - 87s 3s/step - loss: 111703024.0000 - accuracy: 0.1273\n",
            "Epoch 5/10\n",
            "35/35 [==============================] - 88s 3s/step - loss: 1206575488.0000 - accuracy: 0.1129\n",
            "Epoch 6/10\n",
            "35/35 [==============================] - 88s 2s/step - loss: 5793536512.0000 - accuracy: 0.1663\n",
            "Epoch 7/10\n",
            "35/35 [==============================] - 88s 3s/step - loss: 13023725568.0000 - accuracy: 0.1706\n",
            "Epoch 8/10\n",
            "35/35 [==============================] - 87s 2s/step - loss: 14774170624.0000 - accuracy: 0.1184\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - 89s 3s/step - loss: 47785758720.0000 - accuracy: 0.1455\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - 87s 2s/step - loss: 117298118656.0000 - accuracy: 0.1162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# 加载模型\n",
        "model = load_model('path_to_save_model.h5')\n",
        "\n",
        "# 加载和预处理测试图像\n",
        "test_image_path = '/content/drive/MyDrive/ML/UNET/testA/4.png'\n",
        "test_image = Image.open(test_image_path)\n",
        "test_image = test_image.convert('RGB')  # 确保图像是RGB格式\n",
        "test_image = test_image.resize((256, 256))  # 调整图像大小\n",
        "test_image = np.array(test_image) / 255.0  # 归一化图像数据\n",
        "test_image = np.expand_dims(test_image, axis=0)  # 增加批次维度\n",
        "\n",
        "# 使用模型预测\n",
        "predicted_masks = model.predict(test_image)\n",
        "print(predicted_masks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoDBbWI8Hm8n",
        "outputId": "af8830b5-549c-4e3d-c37c-cfa4c4326ac6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 189ms/step\n",
            "[[[[0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.99999994]]\n",
            "\n",
            "  [[0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.99999994]]\n",
            "\n",
            "  [[0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.99999994]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.99999994]]\n",
            "\n",
            "  [[0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.99999994]]\n",
            "\n",
            "  [[0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.99999994 0.         ... 0.         0.\n",
            "    0.        ]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYojhSHZUlwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99HDGszGJwHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}